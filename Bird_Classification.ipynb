{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bird Classification.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1RdvpkZ68i5wbBwbfTKgH_5F2TBNaje5m",
          "timestamp": 1527609847728
        },
        {
          "file_id": "1TlN6uJwK68MrzEx4NaLX0-8zHET8YZPY",
          "timestamp": 1527286687251
        },
        {
          "file_id": "1SmLW-Y7VCP4R-Xxb-aiCCohoE5wbD5-9",
          "timestamp": 1527276819091
        },
        {
          "file_id": "1ZGJbp1h6Mov2jvRim_dopKxyoKKxr5nR",
          "timestamp": 1527262762640
        }
      ],
      "private_outputs": true,
      "collapsed_sections": [
        "oj0fwb78DoIs",
        "9S2hLtG_sqiU",
        "4TLqFeRMFKoB",
        "v4lERFLPD5E4",
        "IHntROSezoT7",
        "hz-L1OcMUFlB",
        "YlbnTo7a84cS",
        "mF3hI8v13Jex",
        "my9Aj64Q3HnQ"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "leyVKGWj1Jor",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#VAST Challenge 2018: MC1 \n",
        "<hr>\n",
        "## Cameron Henkel and Colin Scruggs\n",
        "Credit to [Dr. Jaron Collis](https://github.com/jaron/deep-listening) for providing much of this notebook's source code "
      ]
    },
    {
      "metadata": {
        "id": "c4yke7LsJaM1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Import necessary libraries:**"
      ]
    },
    {
      "metadata": {
        "id": "T70K0V5PpTmy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Uncomment if using a Colaboratory hosted runtime\n",
        "#!pip install -q librosa\n",
        "# from google.colab import files\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8P5ZvFaG84b5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sound Classification & Feature Extraction\n",
        "(local runtime only)"
      ]
    },
    {
      "metadata": {
        "id": "-BfhvLi-84b8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "# Establish variables for parent and save directories \n",
        "parent_dir = './notebook_resources/all-birds-wav'\n",
        "save_dir = './notebook_resources/bird_rnn_features_labels'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9N7CtSDeCuTI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create dataframe from csv containing metadata about each recording\n",
        "datafile = \"./public/data/AllBirdsv4-refined.csv\"\n",
        "df = pd.read_csv(datafile)\n",
        "\n",
        "# Create a copy of the dataframe with entries of quality A, B, or C\n",
        "sample_DF = df.copy()\n",
        "sample_DF = sample_DF[sample_DF['Quality'].isin(['A', 'B', 'C'])]\n",
        "\n",
        "# Append a species id column to the dataframe for labeling purposes\n",
        "Species_ID = sample_DF.English_name.factorize()[0]\n",
        "\n",
        "sample_DF['Species_ID'] = Species_ID\n",
        "\n",
        "# ------------------------------------ #\n",
        "\n",
        "# Fully remove invalid files\n",
        "sample_DF = sample_DF.drop(sample_DF.loc[sample_DF['File ID']==244588].index)\n",
        "sample_DF = sample_DF.drop(sample_DF.loc[sample_DF['File ID']==244587].index)\n",
        "\n",
        "# Remove long audio files and re-add split versions\n",
        "removed_ID = [371463, 327002, 171698, 244585, 325435, 132146, 179051, 256836, 161306, 192536, 306348, 305896, 153038, 206183,\n",
        "             206157, 210466, 163245, 185518]\n",
        "\n",
        "# Modify the csv to include the new file ids of each split audio file\n",
        "for file in os.listdir(\"./notebook_resources/all-birds-wav/bird_splits\"):\n",
        "    file = file[:-4]\n",
        "    orig_ID = file.split(\"-\")[0]\n",
        "    orig_index = sample_DF.loc[sample_DF['File ID']==int(orig_ID)].index.tolist()\n",
        "    temp_species_ID = sample_DF.at[orig_index[0],'Species_ID']\n",
        "    sample_DF = sample_DF.append({'File ID': file,'Species_ID': temp_species_ID}, ignore_index=True)\n",
        "\n",
        "# Remove original long file rows from dataframe to not conflict with the split ones just added\n",
        "for i, value in enumerate(removed_ID):\n",
        "    sample_DF = sample_DF.drop(sample_DF.loc[sample_DF['File ID']==value].index)\n",
        "    \n",
        "# ------------------------------------ #\n",
        "\n",
        "# Grab column of file IDs from bird metadata\n",
        "file_ID = sample_DF['File ID'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dBtr3t2P84b_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define the windowing function of the FFT\n",
        "def windows(data, window_size):\n",
        "    start = 0\n",
        "    while start < len(data):\n",
        "        yield start, start + window_size\n",
        "        start += (window_size // 2)\n",
        "\n",
        "# Extract individual audio features from each recording using MFCC & FFT\n",
        "def extract_features(parent_dir,file_ext=\".wav\",bands = 20, frames = 41):\n",
        "    window_size = 512 * (frames - 1)\n",
        "    mfccs = []\n",
        "    labels = []\n",
        "    ref_ID = []\n",
        "    count_max = len(sample_DF)\n",
        "    # Iterate through every File ID in the dataframe which corresponds to an audio recording\n",
        "    for count, id in enumerate(file_ID):\n",
        "        fn = os.path.join(parent_dir, str(id) + file_ext)\n",
        "        print('Processing %d/%d: %s ...' % (count, count_max, id))\n",
        "        \n",
        "        # Load audio clip into librosa\n",
        "        sound_clip,s = librosa.load(fn)\n",
        "        \n",
        "        # Normalize audio\n",
        "        sound_clip_normalized = librosa.util.normalize(sound_clip)\n",
        "        \n",
        "        # Split audio time series into non-silent sections\n",
        "        split_array = librosa.effects.split(sound_clip_normalized, top_db=10, frame_length=32768, hop_length=256)\n",
        "        split_chirps = []\n",
        "        \n",
        "        # Reform a single time series from the separate non-silent components\n",
        "        for i,interval in enumerate(split_array):\n",
        "            split_chirps.append(librosa.effects.remix(sound_clip_normalized, intervals=[interval]))\n",
        "\n",
        "        # Set classification labels for later machine learning using corresponding Species ID\n",
        "        species_id =  sample_DF.loc[sample_DF['File ID'] == id, 'Species_ID'].tolist()[0]\n",
        "        label = species_id\n",
        "        \n",
        "        # Loop through each individual audio segment (bird chirp) and apply MFCC to generate features\n",
        "        for i, audio_segment in enumerate(split_chirps):\n",
        "            # Uncomment to save individual chirps - consumes a lot of storage space\n",
        "            # save_dir = './bird_rnn_split_wavs'\n",
        "            # file_path = save_dir + \"/\" + str(id) + \"-\" + str(i) + \".wav\"\n",
        "            # librosa.output.write_wav(file_path, audio_segment, sr=s)\n",
        "            for (start,end) in windows(audio_segment,window_size):\n",
        "                start = int(start)\n",
        "                end = int(end)\n",
        "                if(len(audio_segment[start:end]) == window_size):\n",
        "                    signal = audio_segment[start:end]\n",
        "                    mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
        "                    mfccs.append(mfcc)\n",
        "                    labels.append(label)\n",
        "                    ref_ID.append(id)\n",
        "    features = np.asarray(mfccs).reshape(len(mfccs),bands,frames)\n",
        "    return np.array(features), np.array(labels,dtype = np.int), np.array(ref_ID)\n",
        "\n",
        "def one_hot_encode(labels):\n",
        "    n_labels = len(labels)\n",
        "    n_unique_labels = len(np.unique(labels))\n",
        "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
        "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
        "    return one_hot_encode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4SIFdPOTshe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate features and labels from audio files\n",
        "features, labels, ref_ID = extract_features(parent_dir)\n",
        "labels = one_hot_encode(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d6FfX3Uh84cA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Use this to save the features and labels to external files for later reuse\n",
        "def save_folds(data_dir):\n",
        "    print(\"Features = \", features.shape)\n",
        "    print(\"Labels = \", labels.shape)\n",
        "        \n",
        "    feature_file = os.path.join(data_dir, \"Features\" + '_x.npy')\n",
        "    labels_file = os.path.join(data_dir, \"Labels\" + '_y.npy')\n",
        "    ref_file = os.path.join(data_dir, \"References\" + '_y.npy')\n",
        "    np.save(feature_file, features)\n",
        "    print(\"Saved \" + feature_file)\n",
        "    np.save(labels_file, labels)\n",
        "    print(\"Saved \" + labels_file)\n",
        "    np.save(ref_file, ref_ID)\n",
        "    print(\"Saved \" + ref_file)\n",
        "\n",
        "def assure_path_exists(path):\n",
        "    mydir = os.path.join(os.getcwd(), path)\n",
        "    if not os.path.exists(mydir):\n",
        "        os.makedirs(mydir)\n",
        "        \n",
        "# Uncomment this to recreate and save the feature vectors\n",
        "assure_path_exists(save_dir)\n",
        "save_folds(save_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hw8F1kGZ84cC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reload Features and Labels"
      ]
    },
    {
      "metadata": {
        "id": "aGcN8e7C84cD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# This method accesses and returns the Features and Labels (.npy)\n",
        "def driveLoad(base_dir):\n",
        "    print(\"Loading features...\")\n",
        "    feature_file = os.path.join(base_dir+\"Features_x.npy\")\n",
        "    labels_file = os.path.join(base_dir+\"Labels_y.npy\")\n",
        "    loaded_features = np.load(feature_file)\n",
        "    loaded_labels = np.load(labels_file)\n",
        "    \n",
        "    features = loaded_features\n",
        "    labels = loaded_labels\n",
        "    \n",
        "    print(\"Done\")\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oj0fwb78DoIs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reload from Google Drive\n",
        "Must be running in Colaboratory hosted runtime"
      ]
    },
    {
      "metadata": {
        "id": "9S2hLtG_sqiU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### FUSE Google Drive\n",
        "This section is used to establish a connection between our shared Google Drive folder that contains the extracted features and labels .npy files and then load them as local variables.   "
      ]
    },
    {
      "metadata": {
        "id": "F9nwjmzvp0WV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uu4kdz57p5E_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i7CcDTYWp7_q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "# Work around misordering of STREAM and STDIN in Jupyter.\n",
        "# https://github.com/jupyter/notebook/issues/3159\n",
        "prompt = !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass(prompt[0] + '\\n\\nEnter verification code: ')\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "elSq-evyqAgw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvCcTQa1rRhD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Check that Features and Labels are in correct folder\n",
        "!ls drive/all_birds_features_labels/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4TLqFeRMFKoB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Reload features and labels with Drive"
      ]
    },
    {
      "metadata": {
        "id": "Wz8afbDz0ve1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Use load_folds to initialize the features and labels objects from Google Drive\n",
        "\n",
        "features, labels = driveLoad(\"drive/all_birds_features_labels/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4lERFLPD5E4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reload from Local System\n",
        "Must be running in local runtime"
      ]
    },
    {
      "metadata": {
        "id": "3LBf-KB-D8yQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Use load_folds to initialize the features and labels objects from a local filesystem\n",
        "\n",
        "features, labels = driveLoad(\"./notebook_resources/bird_rnn_features_labels/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6mmOQ3884cJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a Recurrent Neural Network with Keras and TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "S5VRScjA84cK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Set random seeds for Tensorflow and Numpy\n",
        "tf.set_random_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l_wGEICrp04y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split loaded data into train/test/validation according to model"
      ]
    },
    {
      "metadata": {
        "id": "qOSyzATLp64u",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Extract random 19 features for predicting\n",
        "prediction_features = [] # One feature from each species\n",
        "\n",
        "# Create splits and assign train, validation, and test data\n",
        "train_test_split = np.random.rand(len(features)) < 0.80 # training and testing split\n",
        "\n",
        "train_x = features[train_test_split]\n",
        "train_y = labels[train_test_split]\n",
        "\n",
        "# From the remaining ~20 percent of features/labels, create a new split for testing and validation data\n",
        "\n",
        "tstv_features = features[~train_test_split]\n",
        "tstv_labels = labels[~train_test_split]\n",
        "\n",
        "train_validate_split = np.random.rand(len(tstv_features)) <0.98 # testing and validation split\n",
        "\n",
        "# Assign validation features and labels (~98%)\n",
        "valid_x = tstv_features[train_validate_split]\n",
        "valid_y = tstv_labels[train_validate_split]\n",
        "\n",
        "# Assign testing features and labels (~2%)\n",
        "test_x = tstv_features[~train_validate_split]\n",
        "test_y = tstv_labels[~train_validate_split]\n",
        "\n",
        "prediction_features=test_x # For later use in 'Test Model' section\n",
        "print(\"Training and validation data loaded.\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7_vxua584cN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate Model\n",
        "These are three machine learning models we used to generate predictions during our research.  \n",
        "We found the RNN LSTM model and the GRU model to be the most accurate.\n",
        "The GRU model generally finished training faster than the RNN LSTM.  \n",
        "  \n",
        "    \n",
        "References:  \n",
        "[RNN, LSTM, and GRU tutorial](https://jhui.github.io/2017/03/15/RNN-LSTM-GRU/)  \n",
        "[Introduction to Long Short Term Memory](https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/)  \n",
        "[Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)"
      ]
    },
    {
      "metadata": {
        "id": "bbUuIgM2z2oW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "data_dim = 41\n",
        "timesteps = 20\n",
        "num_classes = 19"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cS2xoW1qzej_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### RNN LSTM Model \n"
      ]
    },
    {
      "metadata": {
        "id": "cpoHzE1i84cN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# expected input data shape: (batch_size, timesteps, data_dim)\n",
        "model = Sequential()\n",
        "\n",
        "# returns a sequence of vectors of dimension 256\n",
        "model.add(LSTM(512, return_sequences=True, input_shape=(timesteps, data_dim)))  \n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "# returns a sequence of vectors of dimension 256\n",
        "model.add(LSTM(512, return_sequences=True))  \n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# return a single vector of dimension 128\n",
        "model.add(LSTM(256))  \n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "# apply softmax to output\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# compile the model for multi-class classification\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# a stopping function to stop training before we excessively overfit to the training set\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=0, verbose=1, mode='auto')\n",
        "model.fit(train_x, train_y, batch_size=128, epochs=20, callbacks=[earlystop],validation_data=(valid_x, valid_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IHntROSezoT7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Stacked LSTM Model"
      ]
    },
    {
      "metadata": {
        "id": "FbZ6XRyuzrsr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 15\n",
        "\n",
        "# Stacked LSTM\n",
        "# 2nd to last model on https://keras.io/getting-started/sequential-model-guide/\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, return_sequences=True,\n",
        "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
        "model.add(LSTM(128, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
        "model.add(LSTM(128))  # return a single vector of dimension 32\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "# Stateful Stacked LSTM (?)\n",
        "'''\n",
        "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
        "               input_shape=(timesteps, data_dim)))\n",
        "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
        "model.add(LSTM(32, stateful=True))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "'''\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# a stopping function to stop training before we excessively overfit to the training set\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=0, verbose=1, mode='auto')\n",
        "\n",
        "model.fit(train_x, train_y,\n",
        "          batch_size=batch_size, epochs=epochs, callbacks=[earlystop],\n",
        "          validation_data=(valid_x, valid_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hz-L1OcMUFlB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### GRU Model"
      ]
    },
    {
      "metadata": {
        "id": "mmdHmKmhUSh2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import GRU, Dense, Dropout\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#1024\n",
        "model.add(GRU(512, return_sequences=True, input_shape=(timesteps, data_dim)))  \n",
        "model.add(Dropout(0.15))\n",
        "#1024\n",
        "model.add(GRU(512, return_sequences=True))  \n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(GRU(512))  \n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=0, verbose=1, mode='auto')\n",
        "print(\"You're here\")\n",
        "model.fit(train_x, train_y, batch_size=256, epochs=2, callbacks=[earlystop], validation_data=(valid_x, valid_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlbnTo7a84cS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Model"
      ]
    },
    {
      "metadata": {
        "id": "a0mzHem4ICUu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Match species names to correct classification labels\n",
        "species_names = [\"Rose-crested Blue Pipit\", \"Blue-collared Zipper\", \"Bombadil\", \"Broad-winged Jojo\", \"Canadian Cootamum\", \n",
        "                      \"Carries Champagne Pipit\", \"Darkwing Sparrow\", \"Eastern Corn Skeet\", \"Green-tipped Scarlet Pipit\", \n",
        "                      \"Lesser Birchbeere\", \"Orange Pine Plover\", \"Ordinary Snape\", \"Pinkfinch\", \"Purple Tooting Tout\", \n",
        "                      \"Qax\", \"Queenscoat\", \"Bent-beak Riffraff\", \"Scrawny Jay\", \"Vermillion Trillian\"]\n",
        "\n",
        "model_prediction_species = []\n",
        "\n",
        "for oneHot in test_y:\n",
        "    uniqueValues, uniqueIndexes = np.unique(oneHot, return_index=True)\n",
        "    \n",
        "    model_prediction_species.append(species_names[uniqueIndexes[1]])\n",
        "    #print (\"Index: \" + str(index) + \" | \" + species_names[index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aTYSEPVpHWC0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "# Create predictions for each of the sound classes\n",
        "\n",
        "# Variables used to calculate correct percentanges \n",
        "total_correct = 0\n",
        "correct_by_species = []\n",
        "species_correct = 0;\n",
        "species_total = 0;\n",
        "current_species = \"Rose-crested Blue Pipit\"\n",
        "\n",
        "# Loop over each feature set from test data\n",
        "for s in range(len(model_prediction_species)):\n",
        "    \n",
        "    # Handles correct percentages per species\n",
        "    if (current_species != model_prediction_species[s]):\n",
        "        percent = float(species_correct) / species_total\n",
        "        correct_by_species.append(str(current_species) + \": \" + str(percent) + \" (\" + str(species_correct) + \"/\" + str(species_total) + \")\")\n",
        "        species_correct = 0\n",
        "        species_total = 0\n",
        "        \n",
        "    # Grab ground truth for current feature set to be tested against\n",
        "    current_species = model_prediction_species[s]\n",
        "    #print (\"\\n----- \", current_species, \"-----\")\n",
        "    \n",
        "    # Load prediction_features for current_species\n",
        "    predict_x = prediction_features[s]\n",
        "    predict_x = np.expand_dims(predict_x, axis=0)\n",
        "    predictions = model.predict(predict_x)\n",
        "\n",
        "    # If no prediction was able to be generated, print so\n",
        "    if len(predictions) == 0: \n",
        "        print (\"No prediction\")\n",
        "    \n",
        "    # If not, print the top 3 guesses\n",
        "    ind = predictions[0].argsort()[-3:][::-1]\n",
        "    #print (\"Top guess: \", species_names[ind[0]], \" (\",round(predictions[0,ind[0]],3),\")\")\n",
        "    #print (\"2nd guess: \", species_names[ind[1]], \" (\",round(predictions[0,ind[1]],3),\")\")\n",
        "    #print (\"3rd guess: \", species_names[ind[2]], \" (\",round(predictions[0,ind[2]],3),\")\")\n",
        "    \n",
        "    # Accumulate number of correct guesses for percentage calculations\n",
        "    if (species_names[ind[0]] == current_species):\n",
        "        total_correct += 1\n",
        "        species_correct += 1\n",
        "    species_total += 1\n",
        "\n",
        "# Print final results\n",
        "percentCorrect = (float(total_correct) / len(model_prediction_species))\n",
        "print (\"\\n----- Percent correct -----\")\n",
        "print (percentCorrect)\n",
        "print (correct_by_species)\n",
        "for i in correct_by_species: # Print out the percentage correct for each classifier\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "986N8veG-L0q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load/Save Model"
      ]
    },
    {
      "metadata": {
        "id": "LgXw77POxrUq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Saves model to local filesystem root directory\n",
        "\n",
        "fileName = \"insert desired name here\"\n",
        "save_model_name = './notebook_resources/'+fileName + \".h5\"\n",
        "model.save(save_model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fs1nU-rBiF5o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Save Model - Hosted runtime**"
      ]
    },
    {
      "metadata": {
        "id": "QISDxGaPdyZ8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Hosted runtime only - must run previous cell to save model to the Hosted virtual machine's root directory, then the line below downloads that file to the user's local machine\n",
        "\n",
        "#files.download(save_model_name)\n",
        "#print(save_model_name + \" has been saved.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RVMYCjGx6jqV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load Model - Local Runtime**"
      ]
    },
    {
      "metadata": {
        "id": "YlBymrXJ275s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model_file = os.path.join('./notebook_resources/'+fileName+\".h5\")\n",
        "model = load_model(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZjHubCcdXRS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load Model - Hosted Runtime**  \n",
        "Only use if Google Drive has been FUSED and you're on a hosted runtime"
      ]
    },
    {
      "metadata": {
        "id": "AZdFH_o5ryaI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"drive/tensorflow_models/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4vMMNvN85Ug",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_name = \"GRU_19_19.h5\"\n",
        "model = load_model(os.path.join(\"drive/tensorflow_models/\"+model_name))\n",
        "\n",
        "print(model_name + \" has been loaded.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z1oNkXA0qKwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating Kasios Predictions"
      ]
    },
    {
      "metadata": {
        "id": "mF3hI8v13Jex",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Waveform/spectrogram visualization methods"
      ]
    },
    {
      "metadata": {
        "id": "2AltURetLX_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Import necessary libraries:**"
      ]
    },
    {
      "metadata": {
        "id": "aIIKQWYctptK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Uncomment if using a Colaboratory hosted runtime\n",
        "# !pip install -q librosa\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import specgram\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-pastel')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7XRkJec6zW7h",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Defines method for creating a waveform visualization of any sound file\n",
        "def visualizeWave(sound_clip,s,file_ID): \n",
        "    plt.figure(figsize=(20,4))\n",
        "    plt.subplot(1, 1, 1)\n",
        "    librosa.display.waveplot(sound_clip, sr=s)\n",
        "    plt.title(file_ID)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "25DPXXXyudkB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Defines method for creating a spectrogram visualization of any sound file\n",
        "def visualizeSpecgram(sound_clip,file_ID):\n",
        "    fig = plt.figure(figsize=(20,4))\n",
        "    plt.subplot(1,1,1)\n",
        "    specgram(np.array(sound_clip), Fs=22050, cmap=\"hot\")\n",
        "    plt.title(file_ID)\n",
        "    #plt.suptitle('Figure 2: Spectrogram',x=0.5, y=0.95,fontsize=18)\n",
        "    #plt.colorbar(mappable=mappable,ax=ax)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "my9Aj64Q3HnQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature extraction"
      ]
    },
    {
      "metadata": {
        "id": "SuWt28ByqprJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define the windowing function of the FFT\n",
        "def windows(data, window_size):\n",
        "    start = 0\n",
        "    while start < len(data):\n",
        "        yield start, start + window_size\n",
        "        start += (window_size // 2)\n",
        "\n",
        "# Extract individual audio features from each Kasios recording using MFCC & FFT\n",
        "def extract_features(parent_dir,file_ext=\".wav\",bands = 20, frames = 41):\n",
        "    window_size = 512 * (frames - 1)\n",
        "    mfccs = []\n",
        "    file_features_indexes = [0]\n",
        "    chirp_features_indexes = [0]\n",
        "    \n",
        "    for id in range(1,16): # loop through 1-15 (file names of provided Kasios files)\n",
        "        print(\"Processing file \" + str(id) + \"...\")\n",
        "        fn = os.path.join(parent_dir, str(id) + file_ext)\n",
        "        sound_clip,s = librosa.load(fn)\n",
        "        \n",
        "        # --- VISUALIZE RAW AUDIO FILE ---\n",
        "        #visualizeWave(sound_clip, s, id)\n",
        "        #visualizeSpecgram(sound_clip, id)\n",
        "        \n",
        "        split_array = librosa.effects.split(sound_clip, top_db=10, frame_length=32768, hop_length=256)\n",
        "        #print(split_array)\n",
        "        #print(split_array/22050)\n",
        "        split_chirps = []\n",
        "        \n",
        "        for i,interval in enumerate(split_array):\n",
        "            split_chirps.append(librosa.effects.remix(sound_clip, intervals=[interval]))\n",
        "        \n",
        "        # --- VISUALIZE FIRST SPLIT CHIRP ---\n",
        "        #visualizeWave(split_chirps[0], s, id)\n",
        "        #visualizeSpecgram(split_chirps[0], id)\n",
        "        \n",
        "        # --- VISUALIZE REMIXED SPLIT ---\n",
        "        remixed_split = librosa.effects.remix(sound_clip, intervals=librosa.effects.split(sound_clip, top_db=10, frame_length=32768, hop_length=256))\n",
        "        #visualizeWave(remixed_split, s, id)\n",
        "        #visualizeSpecgram(remixed_split, id)\n",
        "        \n",
        "        for i, audio_segment in enumerate(split_chirps):\n",
        "            # --- VISUALIZE EACH CHIRP ---\n",
        "            #visualizeWave(audio_segment, s, (id,i))\n",
        "            #visualizeSpecgram(audio_segment, id)\n",
        "            \n",
        "            # save_dir = './bird_rnn_split_wavs'\n",
        "            # file_path = save_dir + \"/\" + str(id) + \"-\" + str(i) + \".wav\"\n",
        "            # librosa.output.write_wav(file_path, audio_segment, sr=s)\n",
        "            for (start,end) in windows(audio_segment,window_size):\n",
        "                start = int(start)\n",
        "                end = int(end)\n",
        "                #print(start, end, len(sound_clip))\n",
        "                if(len(audio_segment[start:end]) == window_size):\n",
        "                    signal = audio_segment[start:end]\n",
        "                    mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
        "                    mfccs.append(mfcc)\n",
        "            chirp_features_indexes.append(len(mfccs))\n",
        "        file_features_indexes.append(len(mfccs))\n",
        "        print(\"File \" + str(id) + \" done.\\n\")\n",
        "        \n",
        "\n",
        "    features = np.asarray(mfccs).reshape(len(mfccs),bands,frames)\n",
        "    return np.array(features), file_features_indexes, chirp_features_indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ALg702Velda",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Colaboratory hosted runtime / FUSED Drive mode\n",
        "#data_dir = \"drive/test-birds-from-kasios-cleaned/\"\n",
        "\n",
        "# Local runtime / local filesystem mode\n",
        "data_dir = \"./notebook_resources/test-birds-from-kasios-cleaned/\"\n",
        "\n",
        "kasios_features, file_indexes, chirp_indexes = extract_features(data_dir)\n",
        "#print(kasios_features, file_indexes, chirp_indexes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HUi9i2d42zLV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Produce predictions"
      ]
    },
    {
      "metadata": {
        "id": "XlcIgYvN2_et",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "prediction_species = [\"Rose-crested Blue Pipit\", \"Blue-collared Zipper\", \"Bombadil\", \"Broad-winged Jojo\", \"Canadian Cootamum\", \n",
        "                      \"Carries Champagne Pipit\", \"Darkwing Sparrow\", \"Eastern Corn Skeet\", \"Green-tipped Scarlet Pipit\", \n",
        "                      \"Lesser Birchbeere\", \"Orange Pine Plover\", \"Ordinary Snape\", \"Pinkfinch\", \"Purple Tooting Tout\", \n",
        "                      \"Qax\", \"Queenscoat\", \"Bent-beak Riffraff\", \"Scrawny Jay\", \"Vermillion Trillian\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ltCcCYtqpx9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Setup csv column structure for aggregate predictions\n",
        "predictions_DF = pd.DataFrame(columns=['Model_Name', 'ID', 'first_guess', 'first_confidence', 'second_guess', 'second_confidence', 'third_guess', 'third_confidence'])\n",
        "print(predictions_DF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "85GTeLLE5GzW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model_name = \"GRU\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fi3v6kH41GSB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create predictions for each of the bird species\n",
        "\n",
        "for s in range(len(file_indexes) - 1): # s: 0->14\n",
        "    print (\"\\n----- File \", s+1, \"-----\")\n",
        "    \n",
        "    # Load prediction_features for s species\n",
        "    if (s == 0): # if check to prevent overlap  \n",
        "        predict_x = kasios_features[file_indexes[s]: file_indexes[s+1]]\n",
        "        # print(file_indexes[s], file_indexes[s+1])\n",
        "    else:\n",
        "        predict_x = kasios_features[file_indexes[s]+1: file_indexes[s+1]]\n",
        "        # print(file_indexes[s]+1, file_indexes[s+1])\n",
        "    \n",
        "    predictions = model.predict(predict_x)\n",
        "\n",
        "    if len(predictions) == 0: \n",
        "        print (\"No prediction\")\n",
        "    \n",
        "    ind = predictions[0].argsort()[-3:][::-1]\n",
        "\n",
        "    print (\"Top guess: \", prediction_species[ind[0]], \" (\",round(predictions[0,ind[0]],3),\")\")\n",
        "    print (\"2nd guess: \", prediction_species[ind[1]], \" (\",round(predictions[0,ind[1]],3),\")\")\n",
        "    print (\"3rd guess: \", prediction_species[ind[2]], \" (\",round(predictions[0,ind[2]],3),\")\")\n",
        "    predictions_DF = predictions_DF.append({'Model_Name': model_name,'ID': s+1, 'first_guess': prediction_species[ind[0]], 'first_confidence': round(predictions[0,ind[0]],3), 'second_guess': prediction_species[ind[1]], 'second_confidence': round(predictions[0,ind[1]],3), 'third_guess': prediction_species[ind[2]], 'third_confidence': round(predictions[0,ind[2]],3)}, ignore_index=True) \n",
        "\n",
        "print (predictions_DF);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0ofDqeQoP9t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Save prediction data from tests to csv\n",
        "test = pd.DataFrame.to_csv(predictions_DF, path_or_buf='./public/data/aggregate_predictions.csv', encoding='utf-8', index=False)\n",
        "\n",
        "# Download csv from Hosted Runtime\n",
        "#files.download('aggregate_predictions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BaNzMWLmz022",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}